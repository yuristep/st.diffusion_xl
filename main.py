import os
import re
from datetime import datetime
from pathlib import Path
import argparse

from dotenv import load_dotenv
from typing import Optional
import torch


# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env –≤ –∫–æ—Ä–Ω–µ –ª–∏–±–æ –∏–∑ examples/.env
if Path(".env").exists():
    load_dotenv(".env")
elif Path("examples/.env").exists():
    load_dotenv("examples/.env")


# –ï–¥–∏–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 
DEFAULTS = {
    "STEPS": 30,
    "GUIDANCE_SCALE": 5.5,
    "HEIGHT": 768,
    "WIDTH": 512,
}


class Config:
    # –ú–æ–¥–µ–ª—å SDXL (RealVisXL). –ú–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –¥—Ä—É–≥—É—é —Å–æ–≤–º–µ—Å—Ç–∏–º—É—é SDXL.
    MODEL_ID = os.getenv("SDXL_MODEL_ID", "SG161222/RealVisXL_V4.0")
    DEFAULT_STEPS = DEFAULTS["STEPS"]
    DEFAULT_GUIDANCE_SCALE = DEFAULTS["GUIDANCE_SCALE"]
    DEFAULT_HEIGHT = DEFAULTS["HEIGHT"]
    DEFAULT_WIDTH = DEFAULTS["WIDTH"]
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    TORCH_DTYPE = torch.float16 if torch.cuda.is_available() else torch.float32


MODEL_PRESETS = {
    # –ë–∞–∑–æ–≤–∞—è SDXL –æ—Ç Stability AI
    "sdxl_base": {
        "id": "stabilityai/stable-diffusion-xl-base-1.0",
        "pipeline": "StableDiffusionXLPipeline",
        "variant": "fp16",
        "use_safetensors": True,
        "steps_hint": (25, 50),
    },
    # SDXL Turbo ‚Äî —Å–≤–µ—Ä—Ö–±—ã—Å—Ç—Ä–∞—è (1-4 —à–∞–≥–∞)
    "sdxl_turbo": {
        "id": "stabilityai/sdxl-turbo",
        "pipeline": "DiffusionPipeline",
        "variant": "fp16",
        "use_safetensors": True,
        "steps_hint": (1, 4),
    },
    # RealVis XL ‚Äî —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏–∑–º
    "realvisxl": {
        "id": "SG161222/RealVisXL_V4.0",
        "pipeline": "StableDiffusionXLPipeline",
        "variant": "fp16",
        "use_safetensors": True,
        "steps_hint": (20, 40),
    },
    # Juggernaut XL ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è
    "juggernautxl": {
        "id": "RunDiffusion/Juggernaut-XL",
        "pipeline": "DiffusionPipeline",
        "variant": "fp16",
        "use_safetensors": False,
        "steps_hint": (20, 40),
    },
    # DreamShaper XL ‚Äî —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è
    "dreamshaperxl": {
        "id": "lykon/dreamshaper-xl-1-0",
        "pipeline": "DiffusionPipeline",
        "variant": "fp16",
        "use_safetensors": True,
        "steps_hint": (20, 40),
    },
    # Animagine XL ‚Äî –∞–Ω–∏–º–µ/—Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è
    "animaginexl": {
        "id": "cagliostrolab/animagine-xl-3.0",
        "pipeline": "DiffusionPipeline",
        "variant": "fp16",
        "use_safetensors": True,
        "steps_hint": (20, 40),
    },
    # Pony Diffusion XL ‚Äî –∞–Ω–∏–º–µ
    "ponyxl": {
        "id": "stabilityai/stable-diffusion-xl-base-1.0",
        "pipeline": "DiffusionPipeline",
        "variant": "fp16",
        "use_safetensors": True,
        "steps_hint": (20, 40),
    },
    # ZavyChroma XL ‚Äî —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è
    "zavychromaxl": {
        "id": "stablediffusionapi/zavychromaxl",
        "pipeline": "DiffusionPipeline",
        "variant": None,
        "use_safetensors": False,
        "steps_hint": (20, 40),
    },
    # SDXL Lightning ‚Äî —Å–≤–µ—Ä—Ö–±—ã—Å—Ç—Ä–∞—è
    "sdxl_lightning": {
        "id": "ByteDance/SDXL-Lightning",
        "pipeline": "DiffusionPipeline",
        "variant": "fp16",
        "use_safetensors": True,
        "steps_hint": (1, 8),
    },
    # (Flux Schnell —É–¥–∞–ª—ë–Ω –∏–∑ –ø—Ä–µ—Å–µ—Ç–æ–≤ –∫–∞–∫ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–π –≤ —ç—Ç–æ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏)
}


def _resolve_pipeline(pipeline_name: str):
    if pipeline_name == "StableDiffusionXLPipeline":
        from diffusers import StableDiffusionXLPipeline as P
        return P
    if pipeline_name == "DiffusionPipeline":
        from diffusers import DiffusionPipeline as P
        return P
    if pipeline_name == "FluxPipeline":
        from diffusers import FluxPipeline as P
        return P
    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–æ–±—É–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π
    from diffusers import DiffusionPipeline as P
    return P


def initialize_model(model_id_or_key: str, num_steps: Optional[int] = None):
    # –†–∞–∑—Ä–µ—à–∞–µ–º –∫–∞–∫ —è–≤–Ω—ã–π ID, —Ç–∞–∫ –∏ –∫–ª—é—á –ø—Ä–µ—Å–µ—Ç–∞
    preset = MODEL_PRESETS.get(model_id_or_key)
    if preset:
        model_id = preset["id"]
        pipeline_name = preset["pipeline"]
        variant = preset.get("variant")
        use_safetensors = preset.get("use_safetensors", True)
    else:
        model_id = model_id_or_key
        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: SDXL ‚Üí StableDiffusionXLPipeline, –∏–Ω–∞—á–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π
        pipeline_name = "StableDiffusionXLPipeline" if "xl" in model_id.lower() else "DiffusionPipeline"
        variant = "fp16"
        use_safetensors = True

    # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞ –¥–ª—è SDXL Lightning: –±–∞–∑–æ–≤–∞—è SDXL + UNet –∏–∑ ByteDance/SDXL-Lightning
    if model_id_or_key == "sdxl_lightning":
        # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ ByteDance/SDXL-Lightning
        # https://huggingface.co/ByteDance/SDXL-Lightning
        from diffusers import StableDiffusionXLPipeline, UNet2DConditionModel, EulerDiscreteScheduler
        from huggingface_hub import hf_hub_download
        from safetensors.torch import load_file

        print("\nüîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º SDXL Lightning –ø–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ (base + UNet ckpt)...")
        steps = num_steps or 4
        if steps not in {1, 2, 4, 8}:
            print(f"‚ö†Ô∏è SDXL Lightning –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —à–∞–≥–∏ 1/2/4/8. –ò—Å–ø–æ–ª—å–∑—É—é 4.")
            steps = 4

        base_id = "stabilityai/stable-diffusion-xl-base-1.0"
        device = Config.DEVICE
        dtype = Config.TORCH_DTYPE

        # 1) –°–æ–∑–¥–∞—ë–º UNet –ø–æ –∫–æ–Ω—Ñ–∏–≥—É –±–∞–∑–æ–≤–æ–π SDXL –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ lightning ckpt
        unet = UNet2DConditionModel.from_config(base_id, subfolder="unet").to(device, dtype)

        if steps == 1:
            ckpt = "sdxl_lightning_1step_unet_x0.safetensors"
        else:
            ckpt = f"sdxl_lightning_{steps}step_unet.safetensors"

        print(f"üîé –ó–∞–≥—Ä—É–∂–∞—é –≤–µ—Å–∞ UNet: ByteDance/SDXL-Lightning/{ckpt}")
        state = load_file(hf_hub_download("ByteDance/SDXL-Lightning", ckpt), device=device)
        unet.load_state_dict(state)

        # 2) –°–æ–±–∏—Ä–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω —Å –∑–∞–º–µ–Ω—ë–Ω–Ω—ã–º UNet
        pipe = StableDiffusionXLPipeline.from_pretrained(
            base_id,
            unet=unet,
            torch_dtype=dtype,
            variant=(variant if device == "cuda" else None),
        ).to(device)

        # 3) –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (trailing). –î–ª—è 1 —à–∞–≥–∞ ‚Äî prediction_type="sample"
        if steps == 1:
            pipe.scheduler = EulerDiscreteScheduler.from_config(
                pipe.scheduler.config, timestep_spacing="trailing", prediction_type="sample"
            )
        else:
            pipe.scheduler = EulerDiscreteScheduler.from_config(
                pipe.scheduler.config, timestep_spacing="trailing"
            )
    else:
        P = _resolve_pipeline(pipeline_name)
        print("\nüîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å SDXL/Flux...")
        pipe = P.from_pretrained(
            model_id,
            torch_dtype=Config.TORCH_DTYPE,
            variant=(variant if Config.DEVICE == "cuda" else None),
            use_safetensors=use_safetensors,
        )
    pipe = pipe.to(Config.DEVICE)

    # –õ—ë–≥–∫–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è GPU
    if Config.DEVICE == "cuda":
        try:
            pipe.enable_attention_slicing()
        except Exception:
            pass
        try:
            pipe.enable_model_cpu_offload()
        except Exception:
            pass

    print("‚úÖ SDXL —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    return pipe


def truncate_prompt_to_77_tokens(pipe, text: str) -> str:
    """–ë–æ–ª—å—à–µ –Ω–µ –æ–±—Ä–µ–∑–∞–µ—Ç –ø—Ä–æ–º–ø—Ç. –ï—Å–ª–∏ –¥–ª–∏–Ω–∞ > 77 —Ç–æ–∫–µ–Ω–æ–≤, –≤—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.
    –†–µ–∞–ª—å–Ω–∞—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è CLIP (—Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —ç–Ω–∫–æ–¥–µ—Ä–∞) ‚Äî ~77 —Ç–æ–∫–µ–Ω–æ–≤.
    """
    try:
        if not text:
            return text
        tokenizer = getattr(pipe, "tokenizer", None) or getattr(pipe, "tokenizer_2", None)
        if tokenizer is not None:
            encoded = tokenizer(
                text,
                truncation=False,
                return_overflowing_tokens=False,
                return_attention_mask=False,
                add_special_tokens=True,
            )
            input_ids = encoded.get("input_ids", [])
            if input_ids and len(input_ids[0]) > 77:
                print("‚ÑπÔ∏è –ï—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é, —Å–º—ã—Å–ª –ª—É—á—à–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–æ –∏ —ë–º–∫–æ, –Ω–µ –ø—Ä–µ–≤—ã—à–∞—è 77 —Ç–æ–∫–µ–Ω–æ–≤")
        else:
            # –ì—Ä—É–±–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–ª–æ–≤
            words = re.split(r"\s+", text.strip())
            if len(words) > 77:
                print("‚ÑπÔ∏è –ï—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é, —Å–º—ã—Å–ª –ª—É—á—à–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–æ –∏ —ë–º–∫–æ, –Ω–µ –ø—Ä–µ–≤—ã—à–∞—è 77 —Ç–æ–∫–µ–Ω–æ–≤")
        return text
    except Exception:
        return text


def generate_image_sdxl(
    pipe,
    prompt: str,
    negative_prompt: str = None,
    num_inference_steps: int = None,
    guidance_scale: float = None,
    height: int = None,
    width: int = None,
    output_path: str = None,
):
    if output_path is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = f"sdxl_{timestamp}.png"

    if num_inference_steps is None:
        num_inference_steps = Config.DEFAULT_STEPS
    if guidance_scale is None:
        guidance_scale = Config.DEFAULT_GUIDANCE_SCALE
    if height is None:
        height = Config.DEFAULT_HEIGHT
    if width is None:
        width = Config.DEFAULT_WIDTH

    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —É—Å–µ—á–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–æ 77 —Ç–æ–∫–µ–Ω–æ–≤
    safe_prompt = truncate_prompt_to_77_tokens(pipe, prompt)
    safe_negative = truncate_prompt_to_77_tokens(pipe, negative_prompt) if negative_prompt else None

    print("\nüé® SDXL –≥–µ–Ω–µ—Ä–∞—Ü–∏—è...")
    print(f"üìù –ü—Ä–æ–º–ø—Ç: {safe_prompt[:100]}{'...' if len(safe_prompt) > 100 else ''}")
    if safe_negative:
        print(f"üö´ –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π: {safe_negative[:100]}{'...' if len(safe_negative) > 100 else ''}")
    print(f"‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {num_inference_steps} —à–∞–≥–æ–≤, guidance={guidance_scale}, —Ä–∞–∑–º–µ—Ä={width}x{height}")

    result = pipe(
        prompt=safe_prompt,
        negative_prompt=safe_negative,
        num_inference_steps=num_inference_steps,
        guidance_scale=guidance_scale,
        height=height,
        width=width,
    )
    image = result.images[0]
    image.save(output_path)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
    return output_path


def build_arg_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å SDXL/Flux —á–µ—Ä–µ–∑ diffusers",
        add_help=True,
    )
    parser.add_argument(
        "--model",
        default=Config.MODEL_ID,
        help="ID –º–æ–¥–µ–ª–∏ –Ω–∞ Hugging Face (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω --model-key, —Ç–æ –æ–Ω –∏–º–µ–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)",
    )
    parser.add_argument(
        "--model-key",
        choices=sorted(MODEL_PRESETS.keys()),
        help="–ö–ª—é—á –ø—Ä–µ—Å–µ—Ç–∞ –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä. sdxl_base, sdxl_turbo, realvisxl, juggernautxl, ...)",
    )
    parser.add_argument("--prompt", "-p", default=None, help="–¢–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç")
    parser.add_argument("--negative", "-n", default=None, help="–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç")
    parser.add_argument("--steps", type=int, default=Config.DEFAULT_STEPS, help="–ß–∏—Å–ª–æ —à–∞–≥–æ–≤ –¥–∏—Ñ—Ñ—É–∑–∏–∏")
    parser.add_argument("--guidance", type=float, default=Config.DEFAULT_GUIDANCE_SCALE, help="Guidance scale")
    parser.add_argument("--height", type=int, default=Config.DEFAULT_HEIGHT, help="–í—ã—Å–æ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    parser.add_argument("--width", type=int, default=Config.DEFAULT_WIDTH, help="–®–∏—Ä–∏–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    parser.add_argument("--out", "-o", default=None, help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è PNG")
    parser.add_argument("--file", "-f", default=None, help="–ü—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É —Å –ø—Ä–æ–º–ø—Ç–æ–º")
    # –£–¥–∞–ª—ë–Ω–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å —á–µ—Ä–µ–∑ Hugging Face Inference API
    parser.add_argument("--use-inference", action="store_true", help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Hugging Face InferenceClient –≤–º–µ—Å—Ç–æ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏")
    parser.add_argument("--inference-provider", default="fal-ai", help="–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è InferenceClient (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é fal-ai)")
    parser.add_argument("--hf-token", default=None, help="HF_TOKEN, –∏–Ω–∞—á–µ –≤–æ–∑—å–º—ë—Ç—Å—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    # LoRA –¥–ª—è SDXL Lightning
    # LoRA —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤—Ä–µ–º–µ–Ω–Ω–æ —É–±—Ä–∞–Ω
    return parser


def parse_prompt_file(file_path: Path):
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read().strip()
        query_match = re.search(r"#query:\s*\n(.*?)(?=\n#|$)", content, re.DOTALL | re.IGNORECASE)
        negative_match = re.search(r"#negativePrompt:\s*\n(.*?)(?=\n#|$)", content, re.DOTALL | re.IGNORECASE)
        prompt = query_match.group(1).strip() if query_match else content.strip()
        negative_prompt = negative_match.group(1).strip() if negative_match else None
        return prompt, negative_prompt
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
        return None, None


def _model_slug_for_filename(model_id_or_key: str) -> str:
    preset = MODEL_PRESETS.get(model_id_or_key)
    if preset and preset.get("id"):
        source = preset["id"]
    else:
        source = model_id_or_key
    # –ë–µ—Ä—ë–º —Ö–≤–æ—Å—Ç –ø–æ—Å–ª–µ '/', –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ –∑–∞–º–µ–Ω—è–µ–º –Ω–µ-–∞–ª—Ñ–∞–Ω—É–º –Ω–∞ '_'
    name = source.split("/")[-1]
    name = name.lower()
    import re as _re
    name = _re.sub(r"[^a-z0-9]+", "_", name).strip("_")
    return name or "model"


def main():
    parser = build_arg_parser()
    args = parser.parse_args()

    # –ï—Å–ª–∏ –ø—Ä–æ—Å—Ç–æ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç —Å–ø—Ä–∞–≤–∫—É, —Å—é–¥–∞ –Ω–µ –¥–æ–π–¥—ë–º ‚Äî argparse —Å–∞–º –µ—ë –ø–æ–∫–∞–∂–µ—Ç –∏ –≤—ã–π–¥–µ—Ç

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞: –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ –∏–ª–∏ –∏–∑ —Ñ–∞–π–ª–∞
    prompt = args.prompt
    negative = args.negative
    if not prompt and args.file:
        p, n = parse_prompt_file(Path(args.file))
        prompt = prompt or p
        negative = negative or n

    if not prompt:
        print("‚ö†Ô∏è –ù–µ –∑–∞–¥–∞–Ω –ø—Ä–æ–º–ø—Ç. –£–∫–∞–∂–∏—Ç–µ --prompt –∏–ª–∏ --file.")
        return

    # –£–¥–∞–ª—ë–Ω–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å —á–µ—Ä–µ–∑ Hugging Face InferenceClient
    if args.use_inference:
        try:
            from huggingface_hub import InferenceClient
        except Exception:
            print("‚ùå huggingface_hub –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–∞–∫–µ—Ç –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ.")
            return

        token = args.hf_token or os.getenv("HF_TOKEN") or os.getenv("HUGGINGFACEHUB_API_TOKEN")
        if not token:
            print("‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è HF_TOKEN (–∞—Ä–≥—É–º–µ–Ω—Ç --hf-token –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è HF_TOKEN).")
            return

        provider = args.inference_provider
        model_for_inference = args.model if args.model else MODEL_PRESETS.get(args.model_key or "", {}).get("id", "ByteDance/SDXL-Lightning")

        print(f"\n‚òÅÔ∏è –ó–∞–ø—É—Å–∫ —É–¥–∞–ª—ë–Ω–Ω–æ–≥–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: provider={provider}, model={model_for_inference}")
        client = InferenceClient(provider=provider, api_key=token)
        image = client.text_to_image(
            args.prompt,
            model=model_for_inference,
        )
        if args.out:
            out_path = args.out
        else:
            model_slug = _model_slug_for_filename(args.model_key or args.model or model_for_inference)
            out_path = f"{model_slug}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        image.save(out_path)
        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {out_path}")
        return

    # –õ–æ–∫–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º
    model_key = args.model_key
    model_id_or_key = model_key if model_key else args.model

    preset = MODEL_PRESETS.get(model_id_or_key)
    if preset and preset.get("steps_hint"):
        min_s, max_s = preset["steps_hint"]
        if args.steps < min_s or args.steps > max_s:
            print(f"‚ÑπÔ∏è –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ —á–∏—Å–ª–æ —à–∞–≥–æ–≤ –¥–ª—è {model_id_or_key}: {min_s}-{max_s}. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å {args.steps}.")

    pipe = initialize_model(model_id_or_key, num_steps=args.steps)

    # LoRA –æ—Ç–∫–ª—é—á–µ–Ω–∞

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"üíª –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    if device == "cuda":
        try:
            print(f"üéÆ GPU: {torch.cuda.get_device_name()}")
        except Exception:
            pass

    output_path = args.out
    if output_path is None:
        model_slug = _model_slug_for_filename(model_id_or_key)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = f"{model_slug}_{timestamp}.png"
    generate_image_sdxl(
        pipe,
        prompt=prompt,
        negative_prompt=negative,
        num_inference_steps=args.steps,
        guidance_scale=args.guidance,
        height=args.height,
        width=args.width,
        output_path=output_path,
    )


if __name__ == "__main__":
    main()


